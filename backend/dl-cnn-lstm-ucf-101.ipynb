{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1436057,"sourceType":"datasetVersion","datasetId":841381}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import TimeDistributed, LSTM, Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint\n\n# Multi-GPU setup\nstrategy = tf.distribute.MirroredStrategy()\nprint(\"Number of GPUs:\", strategy.num_replicas_in_sync)\n\n# Paths\nVIDEO_ROOT = \"/kaggle/input/ucf101/UCF101/UCF-101\"\nSPLIT_ROOT = \"/kaggle/input/ucf101/UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist\"\nOUTPUT_DIR = \"/kaggle/working/ucf101_frames_subset\"\n\n# Hyperparameters\nIMG_SIZE = 224\nSEQUENCE_LENGTH = 16\nNUM_CLASSES = 101\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nEPOCHS = 15\n\nos.makedirs(OUTPUT_DIR, exist_ok=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T18:10:00.554693Z","iopub.execute_input":"2026-01-04T18:10:00.554971Z","iopub.status.idle":"2026-01-04T18:10:00.565345Z","shell.execute_reply.started":"2026-01-04T18:10:00.554949Z","shell.execute_reply":"2026-01-04T18:10:00.564623Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n","output_type":"stream"},{"name":"stdout","text":"Number of GPUs: 2\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def load_class_indices(path):\n    class_map = {}\n    with open(path, \"r\") as f:\n        for line in f:\n            idx, name = line.strip().split()\n            class_map[name] = int(idx) - 1\n    return class_map\n\nclass_map = load_class_indices(os.path.join(SPLIT_ROOT, \"classInd.txt\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T17:55:17.621197Z","iopub.execute_input":"2026-01-04T17:55:17.621655Z","iopub.status.idle":"2026-01-04T17:55:17.632018Z","shell.execute_reply.started":"2026-01-04T17:55:17.621622Z","shell.execute_reply":"2026-01-04T17:55:17.631314Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def read_split_file(path):\n    samples = []\n    with open(path, \"r\") as f:\n        for line in f:\n            video_path = line.strip().split()[0]\n            class_name = video_path.split(\"/\")[0]\n            label = class_map[class_name]\n            samples.append((video_path, label))\n    return samples\n\ntrain_samples = read_split_file(os.path.join(SPLIT_ROOT, \"trainlist01.txt\"))\ntest_samples = read_split_file(os.path.join(SPLIT_ROOT, \"testlist01.txt\"))\n\n# Select a representative subset to fit Kaggle storage (approx 3000 videos)\nrandom.seed(42)\nsubset_train = random.sample(train_samples, 2500)\nsubset_test = random.sample(test_samples, 500)\n\nprint(\"Subset train videos:\", len(subset_train))\nprint(\"Subset test videos:\", len(subset_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T17:55:17.632960Z","iopub.execute_input":"2026-01-04T17:55:17.633182Z","iopub.status.idle":"2026-01-04T17:55:17.835381Z","shell.execute_reply.started":"2026-01-04T17:55:17.633162Z","shell.execute_reply":"2026-01-04T17:55:17.834676Z"}},"outputs":[{"name":"stdout","text":"Subset train videos: 2500\nSubset test videos: 500\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def extract_frames(video_path, sequence_length=SEQUENCE_LENGTH):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    step = max(total_frames // sequence_length, 1)\n\n    for i in range(sequence_length):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n        frame = frame / 255.0\n        frames.append(frame)\n\n    cap.release()\n\n    # Pad if less than SEQUENCE_LENGTH\n    while len(frames) < sequence_length:\n        frames.append(frames[-1])\n\n    return np.array(frames, dtype=np.float16)  # memory-efficient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T17:55:17.836869Z","iopub.execute_input":"2026-01-04T17:55:17.837088Z","iopub.status.idle":"2026-01-04T17:55:17.842112Z","shell.execute_reply.started":"2026-01-04T17:55:17.837068Z","shell.execute_reply":"2026-01-04T17:55:17.841382Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Pre-extract frames only for subset to fit Kaggle storage\nfor video_rel_path, _ in tqdm(subset_train + subset_test):\n    npy_path = os.path.join(OUTPUT_DIR, video_rel_path.replace(\".avi\", \".npy\"))\n    if not os.path.exists(npy_path):  # avoid re-processing\n        video_full_path = os.path.join(VIDEO_ROOT, video_rel_path)\n        frames = extract_frames(video_full_path)\n        os.makedirs(os.path.dirname(npy_path), exist_ok=True)\n        np.save(npy_path, frames)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T17:55:17.842904Z","iopub.execute_input":"2026-01-04T17:55:17.843131Z","iopub.status.idle":"2026-01-04T18:02:27.236638Z","shell.execute_reply.started":"2026-01-04T17:55:17.843111Z","shell.execute_reply":"2026-01-04T18:02:27.235819Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 3000/3000 [07:09<00:00,  6.99it/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def npy_generator(samples, batch_size=BATCH_SIZE):\n    while True:\n        np.random.shuffle(samples)\n        for i in range(0, len(samples), batch_size):\n            batch_samples = samples[i:i+batch_size]\n            X, y = [], []\n            for video_rel_path, label in batch_samples:\n                npy_path = os.path.join(OUTPUT_DIR, video_rel_path.replace(\".avi\", \".npy\"))\n                frames = np.load(npy_path)\n                X.append(frames)\n                y.append(label)\n            yield np.array(X, dtype=np.float16), tf.one_hot(y, NUM_CLASSES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T18:02:27.237708Z","iopub.execute_input":"2026-01-04T18:02:27.237948Z","iopub.status.idle":"2026-01-04T18:02:27.243023Z","shell.execute_reply.started":"2026-01-04T18:02:27.237926Z","shell.execute_reply":"2026-01-04T18:02:27.242217Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_generator(\n    lambda: npy_generator(subset_train, BATCH_SIZE),\n    output_signature=(\n        tf.TensorSpec(shape=(None, SEQUENCE_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float16),\n        tf.TensorSpec(shape=(None, NUM_CLASSES), dtype=tf.float32)\n    )\n).prefetch(tf.data.AUTOTUNE)\n\ntest_dataset = tf.data.Dataset.from_generator(\n    lambda: npy_generator(subset_test, BATCH_SIZE),\n    output_signature=(\n        tf.TensorSpec(shape=(None, SEQUENCE_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float16),\n        tf.TensorSpec(shape=(None, NUM_CLASSES), dtype=tf.float32)\n    )\n).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T18:02:27.243915Z","iopub.execute_input":"2026-01-04T18:02:27.244124Z","iopub.status.idle":"2026-01-04T18:02:27.316156Z","shell.execute_reply.started":"2026-01-04T18:02:27.244105Z","shell.execute_reply":"2026-01-04T18:02:27.315470Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"with strategy.scope():\n    cnn_base = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n    cnn_base.trainable = False\n\n    model = Sequential([\n        TimeDistributed(cnn_base, input_shape=(SEQUENCE_LENGTH, IMG_SIZE, IMG_SIZE, 3)),\n        TimeDistributed(GlobalAveragePooling2D()),\n        LSTM(128),\n        Dense(128, activation=\"relu\"),\n        Dense(NUM_CLASSES, activation=\"softmax\")\n    ])\n\n    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T18:02:27.317044Z","iopub.execute_input":"2026-01-04T18:02:27.317409Z","iopub.status.idle":"2026-01-04T18:02:30.973586Z","shell.execute_reply.started":"2026-01-04T18:02:27.317379Z","shell.execute_reply":"2026-01-04T18:02:30.972887Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m) │     \u001b[38;5;34m2,257,984\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1280\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m721,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │        \u001b[38;5;34m13,029\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">721,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,029</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,008,933\u001b[0m (11.48 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,008,933</span> (11.48 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m750,949\u001b[0m (2.86 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">750,949</span> (2.86 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n</pre>\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Early stop at target val accuracy\nclass StopAtValAccuracy(Callback):\n    def __init__(self, target=0.85):\n        super().__init__()\n        self.target = target\n\n    def on_epoch_end(self, epoch, logs=None):\n        val_acc = logs.get(\"val_accuracy\")\n        if val_acc and val_acc >= self.target:\n            print(f\"\\nReached {val_acc*100:.2f}% val accuracy. Stopping training.\")\n            self.model.stop_training = True\n\nearly_stop = StopAtValAccuracy(target=0.85)\n\n# Checkpoint\ncheckpoint = ModelCheckpoint(\n    \"best_ucf101_cnn_lstm_model.h5\",\n    monitor=\"val_accuracy\",\n    save_best_only=True,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T18:05:49.553285Z","iopub.execute_input":"2026-01-04T18:05:49.553710Z","iopub.status.idle":"2026-01-04T18:05:49.561921Z","shell.execute_reply.started":"2026-01-04T18:05:49.553675Z","shell.execute_reply":"2026-01-04T18:05:49.561163Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"with strategy.scope():\n    cnn_base = MobileNetV2(\n        weights=\"imagenet\",\n        include_top=False,\n        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n    )\n    cnn_base.trainable = False\n\n    model = Sequential([\n        TimeDistributed(cnn_base, input_shape=(SEQUENCE_LENGTH, IMG_SIZE, IMG_SIZE, 3)),\n        TimeDistributed(GlobalAveragePooling2D()),\n        LSTM(128),\n        Dense(128, activation=\"relu\"),\n        Dense(NUM_CLASSES, activation=\"softmax\")\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-4, clipnorm=1.0),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T18:05:52.166964Z","iopub.execute_input":"2026-01-04T18:05:52.167662Z","iopub.status.idle":"2026-01-04T18:05:53.351277Z","shell.execute_reply.started":"2026-01-04T18:05:52.167633Z","shell.execute_reply":"2026-01-04T18:05:53.350748Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m) │     \u001b[38;5;34m2,257,984\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1280\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m721,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │        \u001b[38;5;34m13,029\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">721,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,029</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,008,933\u001b[0m (11.48 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,008,933</span> (11.48 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m750,949\u001b[0m (2.86 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">750,949</span> (2.86 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n</pre>\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    validation_data=test_dataset,\n    epochs=EPOCHS,\n    steps_per_epoch=len(subset_train)//BATCH_SIZE,\n    validation_steps=len(subset_test)//BATCH_SIZE,\n    callbacks=[early_stop, checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T18:10:12.551620Z","iopub.execute_input":"2026-01-04T18:10:12.551889Z","iopub.status.idle":"2026-01-04T18:23:45.919690Z","shell.execute_reply.started":"2026-01-04T18:10:12.551867Z","shell.execute_reply":"2026-01-04T18:23:45.918838Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.1328 - loss: 4.1782\nEpoch 1: val_accuracy improved from 0.06048 to 0.12500, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 392ms/step - accuracy: 0.1330 - loss: 4.1775 - val_accuracy: 0.1250 - val_loss: 4.0917\nEpoch 2/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.2997 - loss: 3.6231\nEpoch 2: val_accuracy improved from 0.12500 to 0.21774, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.2998 - loss: 3.6225 - val_accuracy: 0.2177 - val_loss: 3.7588\nEpoch 3/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.3958 - loss: 3.1386\nEpoch 3: val_accuracy improved from 0.21774 to 0.25000, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 0.3961 - loss: 3.1377 - val_accuracy: 0.2500 - val_loss: 3.4966\nEpoch 4/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.5389 - loss: 2.6294\nEpoch 4: val_accuracy improved from 0.25000 to 0.30040, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 346ms/step - accuracy: 0.5390 - loss: 2.6290 - val_accuracy: 0.3004 - val_loss: 3.2143\nEpoch 5/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.6485 - loss: 2.2305\nEpoch 5: val_accuracy improved from 0.30040 to 0.33468, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - accuracy: 0.6485 - loss: 2.2301 - val_accuracy: 0.3347 - val_loss: 2.9904\nEpoch 6/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.7271 - loss: 1.8445\nEpoch 6: val_accuracy improved from 0.33468 to 0.35484, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 343ms/step - accuracy: 0.7271 - loss: 1.8443 - val_accuracy: 0.3548 - val_loss: 2.8496\nEpoch 7/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.7825 - loss: 1.5703\nEpoch 7: val_accuracy improved from 0.35484 to 0.38105, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.7825 - loss: 1.5699 - val_accuracy: 0.3810 - val_loss: 2.6621\nEpoch 8/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.8281 - loss: 1.2855\nEpoch 8: val_accuracy did not improve from 0.38105\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 343ms/step - accuracy: 0.8281 - loss: 1.2854 - val_accuracy: 0.3810 - val_loss: 2.5938\nEpoch 9/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.8700 - loss: 1.0952\nEpoch 9: val_accuracy improved from 0.38105 to 0.40121, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 343ms/step - accuracy: 0.8701 - loss: 1.0949 - val_accuracy: 0.4012 - val_loss: 2.4747\nEpoch 10/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9129 - loss: 0.9130\nEpoch 10: val_accuracy did not improve from 0.40121\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 342ms/step - accuracy: 0.9128 - loss: 0.9128 - val_accuracy: 0.3931 - val_loss: 2.4197\nEpoch 11/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9301 - loss: 0.7613\nEpoch 11: val_accuracy improved from 0.40121 to 0.42339, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 0.9302 - loss: 0.7610 - val_accuracy: 0.4234 - val_loss: 2.3620\nEpoch 12/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9444 - loss: 0.6181\nEpoch 12: val_accuracy improved from 0.42339 to 0.43145, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.9444 - loss: 0.6180 - val_accuracy: 0.4315 - val_loss: 2.3106\nEpoch 13/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9547 - loss: 0.5183\nEpoch 13: val_accuracy improved from 0.43145 to 0.44153, saving model to best_ucf101_cnn_lstm_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 344ms/step - accuracy: 0.9547 - loss: 0.5181 - val_accuracy: 0.4415 - val_loss: 2.2867\nEpoch 14/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9767 - loss: 0.4000\nEpoch 14: val_accuracy did not improve from 0.44153\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 343ms/step - accuracy: 0.9767 - loss: 0.4000 - val_accuracy: 0.4355 - val_loss: 2.2608\nEpoch 15/15\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9840 - loss: 0.3413\nEpoch 15: val_accuracy did not improve from 0.44153\n\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 343ms/step - accuracy: 0.9840 - loss: 0.3412 - val_accuracy: 0.4415 - val_loss: 2.2378\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"model.save(\"ucf101_cnn_lstm_final_model.h5\")\nprint(\"Final model saved successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T18:23:45.921308Z","iopub.execute_input":"2026-01-04T18:23:45.921649Z","iopub.status.idle":"2026-01-04T18:23:46.188103Z","shell.execute_reply.started":"2026-01-04T18:23:45.921621Z","shell.execute_reply":"2026-01-04T18:23:46.187317Z"}},"outputs":[{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"Final model saved successfully.\n","output_type":"stream"}],"execution_count":20}]}